---
title: "p8105_hw2_mra2209"
output: github_document

---

author: **Maya Arnott**   
date: **2025-09-19**

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tibble)
library(readxl)
```

# Problem 1 
### Importing pols-month data set:

```{r}
pols_df = (
  read_csv("datasets/pols-month.csv") |> 
    janitor::clean_names()
)

```

### Importing unemployment.csv data set:

```{r}
unemployment_df = (
  read_csv("datasets/unemployment.csv") |> 
    janitor::clean_names()
)
```

### Importing snp.csv data set:

```{r}
snp_df = (
  read_csv("datasets/snp.csv") |> 
    janitor::clean_names()
)
```

### Cleaning the data in pols_df:

```{r}
pols_df <- pols_df |> 
  separate(mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    year = as.integer(year),
    month = month.name[as.integer(month)],
    day = as.integer(day),
    president = case_when(
      prez_dem == 1 ~ "dem",
      prez_gop == 1 ~ "gop",
      TRUE ~ NA_character_  # to get rid of any missing values
    )
  ) |> 
  select(-prez_dem, -prez_gop, -day) #drops old columns
```

### Cleaning the data in snp_df:

```{r}
snp_df <- snp_df |> 
  separate(date, into = c("month", "day", "year"), sep = "/") |> 
  mutate(
    year = as.integer(year),
    month = month.name[as.integer(month)],
    day = as.integer(day),
    year = ifelse(year < 50, year + 2000, year + 1900),
  ) |> 
  select(-day) |>  # drops old column
  select(year, month, close)
```

### Cleaning the data in unemployment_df:

```{r}
unemployment_df <- unemployment_df |> 
  pivot_longer(
    cols = jan:dec,      # pivot these columns
    names_to = "month",  # new name is "month"
    values_to = "unemployment (%)"  # new column is for the values
  )
```

### Joining the data sets:

```{r}
merged_df <- left_join(
  pols_df, snp_df, 
  by = c("year", "month")) |>
  left_join(
    unemployment_df, 
    by = c("year", "month"))
  
```
### Description of data sets:  

The pols-month.csv data set contained 822 observations of 9 variables related to the number of national politicians who are democratic or republican at any given time. I cleaned this data set so that the "mon" column was split into "year", "month", and "day," and replaced the month number with the actual name of the month. The key variables were prez_gop, an indicator of whether the president was republican on the associated date, and prez_dem, an indicator of whether the president was democratic on the associated date. Both columns were binary and had an output of 1 (yes) or 0 (no). I combined these columns into a "president" column, indicating whether the president was democratic or republican for any given date. The years ranged from 1947 to 2015.

The snp.csv data set contained 787 observations of 2 variables related to the S&P, which is often used as a representative measure of the stock market performance as whole. The key variables were "date," which was again split into three columns, and "close," indicating the closing values of the S&P stock index on the given date. The years ranged from 1950 to 2015.

The unemployment.csv data set contained 68 observations of 13 variables. The first column was "year" and every other column was a month out of the year, representing the percentage of unemployment in that particular month in the associated year. I made the data set "longer" so that it can be merged with the other data sets. The years ranged from 1948 to 2015.

The resulting merged data set contains "year" and "month" as the first two columns, since I removed the "day" column from each data set and joined the data sets with these columns as keys. Now we can see whether the president was democratic or republican, the closing values of the S&P, and the unemployment % of each given year/month (if there is data for that year/month). The years ranged from 1947 to 2015. 

# Problem 2

### Importing & cleaning mr. trash wheel data set:

```{r}
mr_trash_wheels_df = (
    # skips first row with figure/drawing
  read_excel("datasets/trash_wheel_collection.xlsx", sheet = "Mr. Trash Wheel", skip = 1) |>  
    janitor::clean_names() |> 
    # removes empty columns and columns not containing trash wheels specific data
    select(-x15, -x16, -homes_powered) |>  
    mutate(
      # converts to an int type & rounds to nearest int
      sports_balls = as.integer(round(sports_balls)), 
      wheel = "Mr. Trash Wheel",
      year = as.integer(year)
     
    )
)
```

### Importing and cleaning prof trash wheel data set:

```{r}
prof_trash_wheels_df = (
  read_excel("datasets/trash_wheel_collection.xlsx", sheet = "Professor Trash Wheel", skip = 1) |>  
  janitor::clean_names() |> 
    select(-homes_powered) |> 
    mutate( 
      wheel = "Professor Trash Wheel",
      year = as.integer(year)
      )
)
  
```

### Importing and cleaning Gwyns trash wheel data set:

```{r}
gwyn_trash_wheel_df = (
  read_excel("datasets/trash_wheel_collection.xlsx", sheet = "Gwynns Falls Trash Wheel", skip = 1) |> 
    janitor::clean_names() |> 
    select(-homes_powered) |> 
    mutate(
      wheel = "Gwynns Trash Wheel",
      year = as.integer(year)
      )
)
```

### Combining all data sets:

```{r}
merged_trash_wheels_df = (
  bind_rows(
    mr_trash_wheels_df, 
    prof_trash_wheels_df, 
    gwyn_trash_wheel_df)
)
```

### Description of merged data set:

The three data sets were combined by using the 'bind_rows' function because the data sets have overlapping columns and represent the same type of observations. I made the decision to stack them vertically, with the addition of the "wheel" column, indicating which trash wheel it came from. In the resulting data set, there are `r nrow(merged_trash_wheels_df)` total observations. By wheel type, mr. trash wheel has `r merged_trash_wheels_df |> filter(wheel == "Mr. Trash Wheel") |> nrow()` observations, professor trash wheel has `r merged_trash_wheels_df |> filter(wheel == "Professor Trash Wheel") |> nrow()` observations, and gwynnda has `r merged_trash_wheels_df |> filter(wheel == "Gwynns Trash Wheel") |>  nrow()` observations. The data set contains the variable 'weight_tons' and 'volume_cubic_yards,' indicating the total amount of litter in tons and the volume of litter in cubic yards, respectively. The next columns show various litter types. The total weight of trash collected by professor trash wheel is `r merged_trash_wheels_df |> filter(wheel == "Professor Trash Wheel") |>  summarise(total = sum(weight_tons, na.rm = TRUE)) |>  pull(total)` tons. The total number of cigarette butts collected by Gwynnda in June of 2022 is `r merged_trash_wheels_df |>  filter(wheel == "Gwynns Trash Wheel") |> summarise(total = sum(weight_tons, na.rm = TRUE)) |>  pull(total)`.

# Problem 3

### Importing and cleaning zip_codes data set:

```{r}
zip_codes_df = (
  read_csv("zillow_data/Zip Codes.csv") |> 
    janitor::clean_names() |> 
    mutate(
      file_date = as.Date(file_date, format = "%m/%d/%y")
    )
)
```

### Importing and cleaning zori data set:

```{r}
zori_df = (
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |> 
  janitor::clean_names() |> 
  rename(
    # take out 'name' in 'county_name' var
    county = county_name, 
    zip_code = region_name) |> 
  select(-region_type) |> 
  mutate(
    # remove the word 'county' in rows
    county = str_remove(county, "County")
  ) |> 
  pivot_longer(
    cols = -c(region_id:county),
    names_to = "file_date",
    values_to= "rental_price"
  ) |> 
  mutate(
    file_date = str_remove(file_date, "^x"),
    file_date = str_replace_all(file_date, "_", "-"), 
    file_date = as.Date(file_date, format = "%Y-%m-%d")
  )
)
```

### Merging the two zillow data sets:

```{r}
merged_zillow_df = (
  full_join(zori_df, zip_codes_df, 
            by = c("zip_code", "county")) |> 
  # to keep only the zillow rental date (time-series)
  rename(file_date = file_date.x) |> 
  # drop the metadata date
  select(-file_date.y) |> 
  select(
        1:3, 
        file_date,
        state_fips:neighborhood, 
        everything())
)
```

I have created a merged data set using the 'full_join' function so that no information from either data set is lost. It joins the data based on the columns 'zip_code,' 'county', and 'file_date,' meaning that if there is matching data in these three columns, they will be returned in the same row. If the data does not match in either data set, it will keep the row but return NA for the missing information. The total observations in the merged data set are `r nrow(merged_zillow_df)`. There are `r merged_zillow_df %>% pull(zip_code) |>  n_distinct()` unique ZIP codes and `r merged_zillow_df |> pull(neighborhood) |>  n_distinct()` unique neighborhoods.

### Finding missing zipcodes:

```{r}
missing_zips = (
  anti_join(
    zip_codes_df, zori_df,
    by = "zip_code"))
 
# count how many are missing
n_missing = nrow(missing_zips)

# view the first few rows
head(missing_zips, 5) 
```

There are `r n_missing` rows that appear in the zip code data set but not in the zillow rental price data set. From looking at the first five missing zip codes, these zip codes may have very small rental listings during the time period, be a owner-heavy neighborhood, or be industrial areas. For example, 10474, in Hunts Point and Mott Haven, features a significant industrial or mixed-use presence.


### Comparing rental prices from Jan 2021 to prices in Jan 2020

```{r echo = FALSE}
# filtering for jan 2020 & jan 2021
jan_data = 
  merged_zillow_df |> 
  filter(month(file_date) == 1, 
         year(file_date) %in%
          c(2020, 2021)) |> 
  select(zip_code, county, neighborhood, file_date, rental_price)
 
# changing to wide format with separate 2020 & 2021 rent columns
jan_wide = 
  jan_data |> 
  mutate(year = year(file_date)) |> 
  select(-file_date) |> 
  pivot_wider(
    names_from = year,
    values_from = rental_price,
    names_prefix = "rent_"
  )

# calculate drop and get top 10 zip codes with largest drop
top_drops = 
  jan_wide |> 
  mutate(rent_drop = rent_2020 - rent_2021) |> 
  arrange(desc(rent_drop)) |> 
  slice_head(n = 10)

top_drops |> 
  mutate(neighborhood = ifelse(is.na(neighborhood), "Unknown", neighborhood))


```


This is a table I created showing the top 10 zip codes withe the largest drop in price from January 2020 to January 2021. All 10 of these zip codes are in Manhattan, which is typically the borough with the highest rental prices, so when there are even moderate percentage drops in the rental prices, the value the price decreases by is still large. The highest drop is $913 in zip code 1007, which was likely influenced by the COVID-19 pandemic.
